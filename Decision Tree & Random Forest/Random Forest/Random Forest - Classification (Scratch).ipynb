{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Random Forest - Classification (Scratch)**"
      ],
      "metadata": {
        "id": "j_TlGBbBWk7F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import Libraries**"
      ],
      "metadata": {
        "id": "AqYOF5R3WgQi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "from sklearn.datasets import load_iris, load_diabetes\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, auc, roc_curve"
      ],
      "metadata": {
        "id": "rIJJk-hU-Eb1"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Code**"
      ],
      "metadata": {
        "id": "QDTE1crtWsPA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Node:\n",
        "    def __init__(self, feature_index, threshold, left, right):\n",
        "        self.feature_index = feature_index\n",
        "        self.threshold = threshold\n",
        "        self.left = left\n",
        "        self.right = right"
      ],
      "metadata": {
        "id": "iKUfSgoPI-78"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LeafNode:\n",
        "    def __init__(self, y):\n",
        "        self.labels, self.counts = np.unique(y, return_counts=True)\n",
        "\n",
        "    def predicted_class(self):\n",
        "        return self.labels[np.argmax(self.counts)]"
      ],
      "metadata": {
        "id": "I2vpc4sJU7tX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecisionTree:\n",
        "    def __init__(self, max_depth=None, min_samples_split=2, criterion=\"gini\"):\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.criterion = criterion\n",
        "        self.tree = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.tree = self._build_tree(X, y)\n",
        "\n",
        "    def _build_tree(self, X, y, depth=0):\n",
        "        num_samples, num_features = X.shape\n",
        "        unique_classes = np.unique(y)\n",
        "\n",
        "        # Check stopping criteria\n",
        "        if len(unique_classes) == 1 or depth >= self.max_depth or num_samples < self.min_samples_split:\n",
        "            return LeafNode(y)\n",
        "\n",
        "        # Find the best split\n",
        "        best_split = self._best_split(X, y, num_features)\n",
        "        if best_split is None:\n",
        "            return LeafNode(y)\n",
        "\n",
        "        left_indices = best_split['indices_left']\n",
        "        right_indices = best_split['indices_right']\n",
        "\n",
        "        left_subtree = self._build_tree(X[left_indices], y[left_indices], depth + 1)\n",
        "        right_subtree = self._build_tree(X[right_indices], y[right_indices], depth + 1)\n",
        "\n",
        "        return Node(best_split['feature_index'], best_split['threshold'], left_subtree, right_subtree)\n",
        "\n",
        "    def _best_split(self, X, y, num_features):\n",
        "        best_gain = -1\n",
        "        best_split = None\n",
        "\n",
        "        for feature_index in range(num_features):\n",
        "            thresholds = np.unique(X[:, feature_index])\n",
        "            for threshold in thresholds:\n",
        "                indices_left = np.where(X[:, feature_index] <= threshold)[0]\n",
        "                indices_right = np.where(X[:, feature_index] > threshold)[0]\n",
        "\n",
        "                if len(indices_left) > 0 and len(indices_right) > 0:\n",
        "                    gain = self._information_gain(y, indices_left, indices_right)\n",
        "                    if gain > best_gain:\n",
        "                        best_gain = gain\n",
        "                        best_split = {\n",
        "                            'feature_index': feature_index,\n",
        "                            'threshold': threshold,\n",
        "                            'indices_left': indices_left,\n",
        "                            'indices_right': indices_right\n",
        "                        }\n",
        "        return best_split\n",
        "\n",
        "    def _information_gain(self, y, left_indices, right_indices):\n",
        "        # Calculate impurity for the split based on the selected criterion\n",
        "        impurity_before = self._impurity(y)\n",
        "        impurity_left = self._impurity(y[left_indices])\n",
        "        impurity_right = self._impurity(y[right_indices])\n",
        "\n",
        "        weighted_impurity = (len(left_indices) / len(y)) * impurity_left + (len(right_indices) / len(y)) * impurity_right\n",
        "        return impurity_before - weighted_impurity\n",
        "\n",
        "    def _impurity(self, y):\n",
        "        if self.criterion == \"gini\":\n",
        "            return self._gini_impurity(y)\n",
        "        elif self.criterion == \"entropy\":\n",
        "            return self._entropy_impurity(y)\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown criterion: {self.criterion}\")\n",
        "\n",
        "    def _gini_impurity(self, y):\n",
        "        classes, counts = np.unique(y, return_counts=True)\n",
        "        probabilities = counts / len(y)\n",
        "        return 1 - np.sum(probabilities ** 2)\n",
        "\n",
        "    def _entropy_impurity(self, y):\n",
        "        classes, counts = np.unique(y, return_counts=True)\n",
        "        probabilities = counts / len(y)\n",
        "        return -np.sum(probabilities * np.log2(probabilities + 1e-15))  # Adding a small value to prevent log(0)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.array([self._traverse_tree(x, self.tree) for x in X])\n",
        "\n",
        "    def _traverse_tree(self, x, tree):\n",
        "        if isinstance(tree, LeafNode):\n",
        "            return tree.predicted_class()\n",
        "        else:\n",
        "            if x[tree.feature_index] <= tree.threshold:\n",
        "                return self._traverse_tree(x, tree.left)\n",
        "            else:\n",
        "                return self._traverse_tree(x, tree.right)\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        probabilities = np.zeros((X.shape[0], len(np.unique(y))))\n",
        "        for i, x in enumerate(X):\n",
        "            class_count = self._traverse_tree_proba(x, self.tree)\n",
        "            total = sum(class_count.values())\n",
        "            for label, count in class_count.items():\n",
        "                probabilities[i, label] = count / total  # Probability for each class\n",
        "        return probabilities\n",
        "\n",
        "    def _traverse_tree_proba(self, x, tree):\n",
        "        if isinstance(tree, LeafNode):\n",
        "            return {label: count for label, count in zip(tree.labels, tree.counts)}\n",
        "        else:\n",
        "            if x[tree.feature_index] <= tree.threshold:\n",
        "                return self._traverse_tree_proba(x, tree.left)\n",
        "            else:\n",
        "                return self._traverse_tree_proba(x, tree.right)"
      ],
      "metadata": {
        "id": "mRKk_KiuVABm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RandomForest:\n",
        "    def __init__(self, n_trees=5, max_depth=10, min_samples_split=2, criterion=\"gini\", loss_function=\"categorical_cross_entropy\"):\n",
        "        self.n_trees = n_trees\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.criterion = criterion\n",
        "        self.loss_function = loss_function\n",
        "        self.trees = []\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        for _ in range(self.n_trees):\n",
        "            tree = DecisionTree(max_depth=self.max_depth, min_samples_split=self.min_samples_split, criterion=self.criterion)\n",
        "            # Bootstrap sampling\n",
        "            sample_indices = np.random.choice(len(X), len(X), replace=True)\n",
        "            X_sample = X[sample_indices]\n",
        "            y_sample = y[sample_indices]\n",
        "            tree.fit(X_sample, y_sample)\n",
        "            self.trees.append(tree)\n",
        "\n",
        "    def predict(self, X):\n",
        "        tree_predictions = np.array([tree.predict(X) for tree in self.trees])\n",
        "        return [Counter(tree_preds).most_common(1)[0][0] for tree_preds in tree_predictions.T]\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        probabilities = np.array([tree.predict_proba(X) for tree in self.trees])\n",
        "        return np.mean(probabilities, axis=0)\n",
        "\n",
        "    def evaluate(self, X, y):\n",
        "        predictions = self.predict(X)\n",
        "        accuracy = np.mean(predictions == y)\n",
        "        loss = self._loss_function(y, self.predict_proba(X))\n",
        "        return accuracy, loss\n",
        "\n",
        "    def _loss_function(self, y_true, y_pred):\n",
        "        if self.loss_function == \"binary_cross_entropy\":\n",
        "            return self._binary_cross_entropy(y_true, y_pred)\n",
        "        elif self.loss_function == \"categorical_cross_entropy\":\n",
        "            return self._categorical_cross_entropy(y_true, y_pred)\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown loss function: {self.loss_function}\")\n",
        "\n",
        "    def _binary_cross_entropy(self, y_true, y_pred):\n",
        "        # Clip predictions to prevent log(0)\n",
        "        epsilon = 1e-15\n",
        "        y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
        "        return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
        "\n",
        "    def _categorical_cross_entropy(self, y_true, y_pred):\n",
        "        epsilon = 1e-15\n",
        "        y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
        "        y_true_one_hot = np.eye(np.max(y_true) + 1)[y_true]\n",
        "        return -np.mean(np.sum(y_true_one_hot * np.log(y_pred), axis=1))"
      ],
      "metadata": {
        "id": "t12DBRwvI_CM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load Dataset**"
      ],
      "metadata": {
        "id": "xv1VI7ZMV2Bh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Iris dataset\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "print(type(X)), print(type(y))\n",
        "print(X.shape), print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWK-dJ3GVET7",
        "outputId": "609e7482-85cf-4809-fb2e-ffbe91d26b59"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "(150, 4)\n",
            "(150,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X[:5])\n",
        "print(y[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F86d21mTGX8l",
        "outputId": "d2c158a2-4f36-49a3-d174-b41645b369c9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[5.1 3.5 1.4 0.2]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [4.6 3.1 1.5 0.2]\n",
            " [5.  3.6 1.4 0.2]]\n",
            "[0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkHYgF5MVdgR",
        "outputId": "96507da0-abc6-46c3-f1af-22f18da29b65"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((120, 4), (30, 4), (120,), (30,))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "forest = RandomForest(n_trees=5, max_depth=10, min_samples_split=2, criterion=\"gini\", loss_function=\"categorical_cross_entropy\")\n",
        "forest.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "pzkhdaTBVh0K"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions\n",
        "predictions = forest.predict(X_test)\n",
        "print(\"Predicted classes:\", predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l52GxJuAVh27",
        "outputId": "981d0c84-f41b-43c6-d0ed-1a29e639ad26"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted classes: [1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2, 0, 2, 2, 2, 2, 2, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate with Gini criterion\n",
        "accuracy, loss = forest.evaluate(X_test, y_test)\n",
        "print(f\"Gini Accuracy: {accuracy * 100:.2f}%\")\n",
        "print(f\"Gini Loss: {loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHeeE0CRVh6j",
        "outputId": "50e08a3d-1be9-4b2a-f292-27fdaa5512c9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gini Accuracy: 100.00%\n",
            "Gini Loss: 0.0223\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(f\"Random Forest Accuracy: {accuracy}\")\n",
        "\n",
        "# Making the Confusion Matrix\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, predictions))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qD7E_OmXOWW",
        "outputId": "35a3dc29-9ce8-4a75-c6ab-12b2fccc45f9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Accuracy: 1.0\n",
            "Confusion Matrix:\n",
            " [[10  0  0]\n",
            " [ 0  9  0]\n",
            " [ 0  0 11]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       1.00      1.00      1.00         9\n",
            "           2       1.00      1.00      1.00        11\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            "\n"
          ]
        }
      ]
    }
  ]
}