{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Decision Tree - Regression (Scratch)**"
      ],
      "metadata": {
        "id": "1J-jm8ZMt824"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import Libraries**"
      ],
      "metadata": {
        "id": "46YyiCUzm1J8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "from sklearn.datasets import load_iris, load_diabetes, fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, explained_variance_score\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, auc, roc_curve"
      ],
      "metadata": {
        "id": "27b4d27OmiJz"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Code**"
      ],
      "metadata": {
        "id": "W80FG82Cm4dA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Node:\n",
        "    def __init__(self, feature=None, threshold=None, left=None, right=None, leaf=False, value=None):\n",
        "        self.feature = feature          # Feature index for splitting\n",
        "        self.threshold = threshold      # Threshold value for splitting\n",
        "        self.left = left                # Left child node\n",
        "        self.right = right              # Right child node\n",
        "        self.leaf = leaf                # Whether this node is a leaf\n",
        "        self.value = value              # Predicted value if it's a leaf"
      ],
      "metadata": {
        "id": "JOXWa2d3msmk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ynEM1n2xmEMm"
      },
      "outputs": [],
      "source": [
        "class DecisionTreeRegressor:\n",
        "    def __init__(self, max_depth=None, min_samples_split=2, criterion='mse'):\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.criterion = criterion\n",
        "        self.tree = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.tree = self._build_tree(X, y)\n",
        "\n",
        "    def _build_tree(self, X, y, depth=0):\n",
        "        # Stopping criteria\n",
        "        if len(y) < self.min_samples_split or (self.max_depth and depth >= self.max_depth):\n",
        "            return self._create_leaf_node(y)\n",
        "\n",
        "        # Find the best split\n",
        "        best_feature, best_threshold = self._find_best_split(X, y)\n",
        "        if best_feature is None:\n",
        "            return self._create_leaf_node(y)\n",
        "\n",
        "        # Split the data\n",
        "        left_indices = X[:, best_feature] < best_threshold\n",
        "        right_indices = X[:, best_feature] >= best_threshold\n",
        "\n",
        "        left_child = self._build_tree(X[left_indices], y[left_indices], depth + 1)\n",
        "        right_child = self._build_tree(X[right_indices], y[right_indices], depth + 1)\n",
        "\n",
        "        return Node(feature=best_feature, threshold=best_threshold, left=left_child, right=right_child)\n",
        "\n",
        "    def _find_best_split(self, X, y):\n",
        "        best_score = np.inf\n",
        "        best_feature = None\n",
        "        best_threshold = None\n",
        "        n_features = X.shape[1]\n",
        "\n",
        "        for feature in range(n_features):\n",
        "            thresholds = np.unique(X[:, feature])\n",
        "            for threshold in thresholds:\n",
        "                score = self._calculate_split_score(X, y, feature, threshold)\n",
        "                if score < best_score:\n",
        "                    best_score = score\n",
        "                    best_feature = feature\n",
        "                    best_threshold = threshold\n",
        "\n",
        "        return best_feature, best_threshold\n",
        "\n",
        "    def _calculate_split_score(self, X, y, feature, threshold):\n",
        "        # Split the data\n",
        "        left_indices = X[:, feature] < threshold\n",
        "        right_indices = X[:, feature] >= threshold\n",
        "\n",
        "        if np.sum(left_indices) == 0 or np.sum(right_indices) == 0:\n",
        "            return np.inf  # Avoid invalid split\n",
        "\n",
        "        if self.criterion == 'mse':\n",
        "            return self._mean_squared_error(y, left_indices, right_indices)\n",
        "        elif self.criterion == 'mae':\n",
        "            return self._mean_absolute_error(y, left_indices, right_indices)\n",
        "\n",
        "    def _mean_squared_error(self, y, left_indices, right_indices):\n",
        "        left_mse = np.mean((y[left_indices] - np.mean(y[left_indices])) ** 2)\n",
        "        right_mse = np.mean((y[right_indices] - np.mean(y[right_indices])) ** 2)\n",
        "\n",
        "        # Weighted MSE\n",
        "        total_samples = len(y)\n",
        "        return (np.sum(left_indices) / total_samples) * left_mse + (np.sum(right_indices) / total_samples) * right_mse\n",
        "\n",
        "    def _mean_absolute_error(self, y, left_indices, right_indices):\n",
        "        left_mae = np.mean(np.abs(y[left_indices] - np.mean(y[left_indices])))\n",
        "        right_mae = np.mean(np.abs(y[right_indices] - np.mean(y[right_indices])))\n",
        "\n",
        "        # Weighted MAE\n",
        "        total_samples = len(y)\n",
        "        return (np.sum(left_indices) / total_samples) * left_mae + (np.sum(right_indices) / total_samples) * right_mae\n",
        "\n",
        "    def _create_leaf_node(self, y):\n",
        "        value = np.mean(y)  # Use mean value for regression\n",
        "        return Node(leaf=True, value=value)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.array([self._predict_sample(sample, self.tree) for sample in X])\n",
        "\n",
        "    def _predict_sample(self, sample, tree):\n",
        "        if tree.leaf:\n",
        "            return tree.value\n",
        "\n",
        "        if sample[tree.feature] < tree.threshold:\n",
        "            return self._predict_sample(sample, tree.left)\n",
        "        else:\n",
        "            return self._predict_sample(sample, tree.right)\n",
        "\n",
        "    def print_tree(self, tree=None, indent=\"  \"):\n",
        "        \"\"\"Prints the structure of the decision tree\"\"\"\n",
        "        if tree is None:\n",
        "            tree = self.tree\n",
        "        if tree.leaf:\n",
        "            print(f\"{indent}Leaf: Value {tree.value:.2f}\")\n",
        "        else:\n",
        "            print(f\"{indent}Feature {tree.feature} <= {tree.threshold:.2f}\")\n",
        "            print(f\"{indent}Left:\")\n",
        "            self.print_tree(tree.left, indent + \"  \")\n",
        "            print(f\"{indent}Right:\")\n",
        "            self.print_tree(tree.right, indent + \"  \")\n",
        "\n",
        "    def accuracy(self, y, y_hat):\n",
        "        return np.mean((y - y_hat) ** 2)  # Return mean squared error for regression\n",
        "\n",
        "    def mean_squared_error(self, y_true, y_pred):\n",
        "        return np.mean((y_true - y_pred) ** 2)\n",
        "\n",
        "    def mean_absolute_error(self, y_true, y_pred):\n",
        "        return np.mean(np.abs(y_true - y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load Dataset**"
      ],
      "metadata": {
        "id": "e3iJTqdhmyN7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the California housing dataset\n",
        "# data = fetch_california_housing()\n",
        "data = load_diabetes()\n",
        "X = data.data\n",
        "y = data.target\n",
        "print(X.shape), print(y.shape)\n",
        "print(X[:5])\n",
        "print(y[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDSiFApomugz",
        "outputId": "27d3994b-e6f5-41be-f998-6bd907ed7940"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(442, 10)\n",
            "(442,)\n",
            "[[ 0.03807591  0.05068012  0.06169621  0.02187239 -0.0442235  -0.03482076\n",
            "  -0.04340085 -0.00259226  0.01990749 -0.01764613]\n",
            " [-0.00188202 -0.04464164 -0.05147406 -0.02632753 -0.00844872 -0.01916334\n",
            "   0.07441156 -0.03949338 -0.06833155 -0.09220405]\n",
            " [ 0.08529891  0.05068012  0.04445121 -0.00567042 -0.04559945 -0.03419447\n",
            "  -0.03235593 -0.00259226  0.00286131 -0.02593034]\n",
            " [-0.08906294 -0.04464164 -0.01159501 -0.03665608  0.01219057  0.02499059\n",
            "  -0.03603757  0.03430886  0.02268774 -0.00936191]\n",
            " [ 0.00538306 -0.04464164 -0.03638469  0.02187239  0.00393485  0.01559614\n",
            "   0.00814208 -0.00259226 -0.03198764 -0.04664087]]\n",
            "[151.  75. 141. 206. 135.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HSi1STJmuo1",
        "outputId": "55f27a1a-1a0c-4fb5-eb5a-6b2358557bf0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((353, 10), (89, 10), (353,), (89,))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "tree = DecisionTreeRegressor(max_depth=5, min_samples_split=4, criterion='mae')\n",
        "tree.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "JNYNTtm_npr6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Decision Tree Structure:\")\n",
        "tree.print_tree()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbOErlYgswQG",
        "outputId": "90679ff6-23d0-4d99-d444-f02570106215"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Structure:\n",
            "  Feature 2 <= 0.01\n",
            "  Left:\n",
            "    Feature 8 <= -0.00\n",
            "    Left:\n",
            "      Feature 8 <= -0.03\n",
            "      Left:\n",
            "        Feature 3 <= 0.13\n",
            "        Left:\n",
            "          Feature 0 <= 0.08\n",
            "          Left:\n",
            "            Leaf: Value 83.55\n",
            "          Right:\n",
            "            Leaf: Value 199.00\n",
            "        Right:\n",
            "          Leaf: Value 216.00\n",
            "      Right:\n",
            "        Feature 5 <= 0.10\n",
            "        Left:\n",
            "          Feature 4 <= -0.05\n",
            "          Left:\n",
            "            Leaf: Value 141.11\n",
            "          Right:\n",
            "            Leaf: Value 100.57\n",
            "        Right:\n",
            "          Leaf: Value 241.50\n",
            "    Right:\n",
            "      Feature 7 <= 0.11\n",
            "      Left:\n",
            "        Feature 5 <= -0.04\n",
            "        Left:\n",
            "          Feature 0 <= 0.07\n",
            "          Left:\n",
            "            Leaf: Value 180.11\n",
            "          Right:\n",
            "            Leaf: Value 283.00\n",
            "        Right:\n",
            "          Feature 6 <= 0.03\n",
            "          Left:\n",
            "            Leaf: Value 158.85\n",
            "          Right:\n",
            "            Leaf: Value 107.62\n",
            "      Right:\n",
            "        Feature 0 <= -0.03\n",
            "        Left:\n",
            "          Leaf: Value 292.00\n",
            "        Right:\n",
            "          Leaf: Value 242.00\n",
            "  Right:\n",
            "    Feature 2 <= 0.07\n",
            "    Left:\n",
            "      Feature 8 <= 0.04\n",
            "      Left:\n",
            "        Feature 3 <= 0.10\n",
            "        Left:\n",
            "          Feature 2 <= 0.03\n",
            "          Left:\n",
            "            Leaf: Value 186.03\n",
            "          Right:\n",
            "            Leaf: Value 145.65\n",
            "        Right:\n",
            "          Leaf: Value 282.00\n",
            "      Right:\n",
            "        Feature 0 <= -0.06\n",
            "        Left:\n",
            "          Leaf: Value 102.50\n",
            "        Right:\n",
            "          Feature 3 <= 0.06\n",
            "          Left:\n",
            "            Leaf: Value 214.81\n",
            "          Right:\n",
            "            Leaf: Value 257.42\n",
            "    Right:\n",
            "      Feature 0 <= -0.06\n",
            "      Left:\n",
            "        Leaf: Value 200.00\n",
            "      Right:\n",
            "        Feature 2 <= 0.16\n",
            "        Left:\n",
            "          Feature 6 <= -0.07\n",
            "          Left:\n",
            "            Leaf: Value 341.00\n",
            "          Right:\n",
            "            Leaf: Value 267.87\n",
            "        Right:\n",
            "          Leaf: Value 346.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions\n",
        "y_pred = tree.predict(X_test)\n",
        "print(y_pred[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7wGZMnon3tj",
        "outputId": "074aa439-2c70-40f8-c614-4aa6cda765ba"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[158.85185185 145.65384615 107.61538462 257.41666667 100.56603774]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate MSE and MAE\n",
        "mse = tree.mean_squared_error(y_test, y_pred)\n",
        "mae = tree.mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "print(f\"MSE: {mse:.2f}\")\n",
        "print(f\"MAE: {mae:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJRCOXPvnF0_",
        "outputId": "79b93e88-9786-4c3e-ba8a-93a181541efd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 3967.26\n",
            "MAE: 48.21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inbuilt Accuracies\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "evs = explained_variance_score(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error :\", mse)\n",
        "print(f\"Mean Absolute Error :\", mae)\n",
        "print(f\"Explained Variance Score :\", evs)\n",
        "print(f\"R2 Score :\", r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZE_e5ZUnF3U",
        "outputId": "37efca25-d4d4-455e-dafc-d5dbc659f7f4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error : 3967.255731354888\n",
            "Mean Absolute Error : 48.209498060388846\n",
            "Explained Variance Score : 0.2512521998502245\n",
            "R2 Score : 0.25120005623363717\n"
          ]
        }
      ]
    }
  ]
}